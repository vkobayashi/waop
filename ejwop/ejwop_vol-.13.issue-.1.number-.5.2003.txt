Two experimental studies investigated the impact of format and instructions on the validity of SAs, using participants applying for junior management positions in a public sector organization. In Study 1 (607 participants) self-assessments (SAs) were valid when applicants rated overall competencies or the same competencies broken down into discrete elements, but not when providing behavioural evidence prior to rating competencies. The effect of social comparison instructions was also explored but found to have no impact on validity. Study 2 used a subset of 193 candidates from the previous study who attended the next stage of the selection process. Consistent with predictions it was found that unbalanced, positively toned scales were more valid than conventional scales, and highest validities were achieved when used with instructions requesting a realistic SA of strengths and weaknesses. Interestingly, gender differences were found in both studies. These findings are discussed in terms of their implications for both research and practice.
